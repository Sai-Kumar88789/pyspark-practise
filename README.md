# Pyspark

### Uses of Pyspark
PySpark is a Spark library written in Python to run Python applications using Apache Spark capabilities. Using PySpark we can run applications parallelly on the distributed cluster (multiple nodes) or even on a single node.

1. When we use a huge amount of datasets, then pandas can be slow to operate but the spark has an inbuilt API to operate data, which makes it faster than pandas.
2. Easier to implement than pandas, Spark has easy to use API.
3. Spark supports Python, Scala, Java & R
4. ANSI SQL compatibility in Spark.
5. Spark uses in-memory(RAM) for computation.
6. It support parallaization.